{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impostazione iniziale codice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "#reset variabili \n",
    "\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "from keras import layers, models\n",
    "import keras \n",
    "import os\n",
    "import timm\n",
    "import tensorflow\n",
    "#os.environ['CURL_CA_BUNDLE'] = ''\n",
    "\n",
    "import numpy\n",
    "import json\n",
    "import pickle\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "numpy.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# variante di BERT preaddestrata in compiti similari\n",
    "models = [\"cardiffnlp/twitter-roberta-large-emotion-latest\",\n",
    "          #\"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\",\n",
    "          \"sileod/deberta-v3-small-tasksource-nli\"\n",
    "          ]\n",
    "\n",
    "\n",
    "md = []\n",
    "# ottenimento tokenizer e modello BERT pre-addestrato\n",
    "for model in models:\n",
    "    # codice per caricare tutto offline\n",
    "    #model = (\"models/\"+model).replace(\"/\",\"--\")\n",
    "    #cached = \"C:\\\\Users\\\\USER\\\\.cache\\\\huggingface\\\\hub\\\\\"\n",
    "    #model = cached+model+\"\\\\snapshots\\\\\"\n",
    "    #model = model +\"\\\\\"+os.listdir(model)[0] + \"\\\\\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model)#,local_files_only=True)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model,output_hidden_states=True)#,local_files_only=True)\n",
    "    md.append((tokenizer,model))\n",
    "\n",
    "# Estrazione features da CNN\n",
    "# Mobilenetv3 fa preprocessing automatico\n",
    "\n",
    "tf_models = [\n",
    "    (keras.applications.MobileNetV3Large,'expanded_conv_14_squeeze_excite_avg_pool','imagenet'),\n",
    "    ]\n",
    "timm_models = [\n",
    "    (\"hf_hub:timm/mobilenetv4_hybrid_large.e600_r384_in1k\",\"test\"),\n",
    "               ]\n",
    "cnns = []\n",
    "for model in tf_models:\n",
    "    # Estrazione features https://keras.io/api/applications/#usage-examples-for-image-classification-models\n",
    "    base_model = model[0](weights=model[2], include_top=False)\n",
    "    pooling_layer = model[1]\n",
    "    #base_model.summary(line_length = 200)\n",
    "    #modello di estrazione di features dal global average pooling\n",
    "    CNN = keras.models.Model(inputs=base_model.input, outputs=base_model.get_layer(pooling_layer).output)\n",
    "    cnns.append((CNN,\"tf\"))\n",
    "\n",
    "for model in timm_models:\n",
    "    base_model = timm.create_model(model[0], pretrained=True,num_classes=0)\n",
    "    base_model.eval()\n",
    "    data_config = timm.data.resolve_model_data_config(base_model)\n",
    "    transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "    def cn(val):\n",
    "        data = transforms(val).unsqueeze(0)\n",
    "        return base_model(data)\n",
    "    cnns.append((cn,\"torch\"))\n",
    "\n",
    "base_path = os.path.dirname(os.path.abspath(\"__file__\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impostazione path di base del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainpath = base_path + \"\\\\train\"\n",
    "trainjson = trainpath+\"\\\\train.json\"\n",
    "train_images = trainpath+\"\\\\train_images\\\\\"\n",
    "\n",
    "\n",
    "testpath = base_path + \"\\\\test\"\n",
    "testjson = testpath+\"\\\\en_subtask2a_test_unlabeled.json\"\n",
    "test_images = testpath+\"\\\\test_images\\\\\"\n",
    "\n",
    "validation_path = base_path + \"\\\\validation\"\n",
    "validationjson = validation_path+ \"\\\\validation.json\"\n",
    "validation_images = validation_path+\"\\\\validation_images\\\\\"\n",
    "\n",
    "devpath = base_path + \"\\\\dev\"\n",
    "devjson = devpath+\"\\\\dev_subtask2a_en.json\"\n",
    "dev_images = devpath+\"\\\\dev_images\\\\\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainpath = base_path + \"\\\\train\"\n",
    "trainjson = trainpath+\"\\\\train_2b.json\"\n",
    "train_images = trainpath+\"\\\\train_images\\\\\"\n",
    "\n",
    "\n",
    "testpath = base_path + \"\\\\test\"\n",
    "testjson = testpath+\"\\\\en_subtask2b_test_unlabeled.json\"\n",
    "test_images = testpath+\"\\\\test_images\\\\\"\n",
    "\n",
    "validation_path = base_path + \"\\\\validation\"\n",
    "validationjson = validation_path+ \"\\\\val_2b.json\"\n",
    "validation_images = validation_path+\"\\\\validation_images\\\\\"\n",
    "\n",
    "devpath = base_path + \"\\\\dev\"\n",
    "devjson = devpath+\"\\\\dev_subtask2b_en.json\"\n",
    "dev_images = devpath+\"\\\\dev_images\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estrazione info generiche da dataset di cui:\n",
    "* numero classi\n",
    "* probabilità varie(alcune scartate)\n",
    "* label dele classi\n",
    "* statistiche del numero di label per istanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the classes\n",
    "task = 1\n",
    "with open(trainjson,\"r\",encoding=\"utf8\") as f:\n",
    "    trainreadjson = json.load(f)\n",
    "\n",
    "var = set()\n",
    "meancalc = []\n",
    "for elem in trainreadjson:\n",
    "    if(task == 0):\n",
    "\n",
    "        if len(var)>23:\n",
    "            break\n",
    "        for j in elem[\"labels\"]:\n",
    "            var.add(j)\n",
    "    else:\n",
    "        if len(var)>2:\n",
    "            break\n",
    "        var.add(elem[\"label\"])\n",
    "#print(var)\n",
    "var = sorted(var)\n",
    "prob = dict.fromkeys(var, 0)\n",
    "if task == 0:\n",
    "    prob_2 = dict.fromkeys(range(9),0)\n",
    "else:\n",
    "    prob_2 = dict.fromkeys(var, 0)\n",
    "total = 0\n",
    "for elem in trainreadjson:\n",
    "    if(task == 0):\n",
    "        prob_2[len(elem[\"labels\"])] += 1\n",
    "        for j in elem[\"labels\"]:\n",
    "            prob[j] += 1\n",
    "            total += 1\n",
    "    else:\n",
    "        prob_2[elem[\"label\"]] += 1\n",
    "        prob[elem[\"label\"]] += 1\n",
    "        total += 1\n",
    "\n",
    "for key in prob.keys():\n",
    "    prob[key] = prob[key]/total\n",
    "\n",
    "final_prob_vec = []\n",
    "for elem in var:\n",
    "    final_prob_vec.append(prob[elem])\n",
    "print(prob_2)\n",
    "for elem in prob_2.keys():\n",
    "    prob_2[elem] = prob_2[elem]/total\n",
    "print(prob_2)\n",
    "#var\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estrazione embeddings testuali e unione di essi alle features dalle immagini dei vari dataset usati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_embeddings(json,imagepath):\n",
    "    leghjson = len(json)\n",
    "    extracted_unit = 0\n",
    "    for value in json:\n",
    "        value[\"tokenized\"] = []\n",
    "        #value[\"context_full_embedding\"] = []\n",
    "        value[\"context_CLS_embedding\"] = []\n",
    "        value[\"context_no_CLS_embedding\"] = []\n",
    "        tokenized = None\n",
    "        for mod in md:\n",
    "            tokenizer = mod[0]\n",
    "            model = mod[1]\n",
    "            #print(value[\"labels\"])\n",
    "            # estrazione embeddings\n",
    "            try:\n",
    "                tokenized = tokenizer(value[\"text\"],return_tensors=\"pt\")\n",
    "                v = model(**tokenized)\n",
    "            except RuntimeError:\n",
    "                print(\"cut\")\n",
    "                # handling di testi troppo lunghi, estraggo la parte centrale dato che si suppone la più importante\n",
    "                leng_token = len(value[\"text\"])//3\n",
    "                tokenized = tokenizer(value[\"text\"][leng_token:2*leng_token],return_tensors=\"pt\")\n",
    "                v = model(**tokenized)\n",
    "            # estrazione ultimo layer di logits\n",
    "            value[\"tokenized\"].append(tokenized)\n",
    "            last_layer = v.hidden_states[-1][0].detach().numpy()\n",
    "\n",
    "            # salvataggio embedding perchè potrebbe tornare utile\n",
    "            #value[\"context_full_embedding\"].append(last_layer)\n",
    "\n",
    "            # sono stati effettuati diversi test su quale embedding delle frasi fosse migliore e se escludere il CLS,\n",
    "            # ma alla fine è stato utilizzato comunque quello\n",
    "            value[\"context_CLS_embedding\"].append(last_layer[0])\n",
    "\n",
    "            # due embeddings in cui si fa la media e nell'altro la normalizzazione \n",
    "            # degli altri vettori dell'embedding senza il CLS\n",
    "            #value[\"context_AVG_embedding\"] = tensorflow.math.reduce_sum(last_layer[1:],axis=0)/numpy.mean(last_layer[1:],axis=0)\n",
    "            last_layer = tensorflow.math.reduce_sum(last_layer[1:],axis=0)\n",
    "            last_layer = last_layer/numpy.linalg.norm(last_layer,2)\n",
    "            value[\"context_no_CLS_embedding\"].append(last_layer)\n",
    "        value[\"image_embedding\"] = []\n",
    "        for CNN in cnns:\n",
    "            if(CNN[1] == \"tf\"):\n",
    "                #estrazione degli embeddings dalle immagini\n",
    "                image = keras.utils.img_to_array(keras.utils.load_img(imagepath+value[\"image\"]))\n",
    "                image = numpy.expand_dims(image, axis=0)\n",
    "                image = CNN[0].predict(image,verbose=0)\n",
    "        \n",
    "                while type(image[0]) == numpy.ndarray:\n",
    "                    image = image[0]\n",
    "                value[\"image_embedding\"].append(image)\n",
    "            else:\n",
    "                image =Image.open(imagepath+value[\"image\"]).convert('RGB')\n",
    "                image = CNN[0](image)\n",
    "                image = image.detach().numpy()\n",
    "                while type(image[0]) == numpy.ndarray:\n",
    "                    image = image[0]\n",
    "                value[\"image_embedding\"].append(image)\n",
    "            \n",
    "        # estrazione dei label ove disponibili(il try catch serve per i casi in cui non ci sono i label)\n",
    "        try:\n",
    "            if(task == 0):\n",
    "                \n",
    "                value[\"y\"] = [1 if(x in value[\"labels\"]) else 0 for x in var]\n",
    "                sum = numpy.sum(value[\"y\"])\n",
    "                value[\"y\"] = value[\"y\"]\n",
    "                value[\"y_total\"] = [1 if(x+1 == sum) else 0 for x in range(len(prob_2.keys()))]\n",
    "            else:\n",
    "                value[\"y\"] = [1 if(x == value[\"label\"]) else 0 for x in var]\n",
    "        except:\n",
    "            pass\n",
    "        extracted_unit += 1\n",
    "        #percentuale di completamento estrazione\n",
    "        print(extracted_unit/leghjson)\n",
    "# concatenazione embeddings testuali e di immagine e creazione metrice di input per le reti neurali\n",
    "def convert_to_model(dataset,cls=True,old=False):\n",
    "\n",
    "    if cls:\n",
    "        val = \"context_CLS_embedding\"\n",
    "    else:\n",
    "        val = \"context_no_CLS_embedding\"\n",
    "    if old:\n",
    "        val = \"context_AVG_embedding\"\n",
    "    few = dataset\n",
    "    # concatenazione di tutti gli embeddings in modo da vedere se riesco a tirare fuori qualcosa da più modelli\n",
    "\n",
    "    input_x = []\n",
    "    for v in few:\n",
    "        var = []\n",
    "        for j in v[val]:\n",
    "            var.append(j)\n",
    "        for j in v[\"image_embedding\"]:\n",
    "            var.append(j)\n",
    "        var = numpy.concatenate(var)\n",
    "        var = var.flatten()\n",
    "        input_x.append(var)\n",
    "\n",
    "    input_x = numpy.array(input_x)\n",
    "    try:\n",
    "        y = numpy.array([v[\"y\"] for v in few])\n",
    "        if(task == 0):\n",
    "\n",
    "            y_total = numpy.array([v[\"y_total\"] for v in few])\n",
    "        else:\n",
    "            y_total = []\n",
    "        return(input_x,y,y_total)\n",
    "    except:\n",
    "        return input_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vera estrazione features e salvataggio in variabili\n",
    "#### l'estrazione features è molto lunga, lo script fa in modo da salvare le features estratte in modo che l'estrazione sia fatta una volta sola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "file = Path(\"./objs.pkl\")\n",
    "if not file.exists():\n",
    "    with open(trainjson,\"r\",encoding=\"utf8\") as f:\n",
    "        trainreadjson = json.load(f)\n",
    "    train = trainreadjson#[0:trainsize]\n",
    "    preprocess_embeddings(train,train_images)\n",
    "\n",
    "    with open(testjson,\"r\",encoding=\"utf8\") as f:\n",
    "        testreadjson = json.load(f)\n",
    "    test = testreadjson\n",
    "    preprocess_embeddings(test,test_images)\n",
    "\n",
    "    with open(validationjson,\"r\",encoding=\"utf8\") as f:\n",
    "        validreadjson = json.load(f)\n",
    "    validat_x = validreadjson\n",
    "    preprocess_embeddings(validat_x,validation_images)\n",
    "\n",
    "    with open(devjson,\"r\",encoding=\"utf8\") as f:\n",
    "        devreadjson = json.load(f)\n",
    "    dev_x = devreadjson\n",
    "    preprocess_embeddings(dev_x,dev_images)\n",
    "    # salvataggio oggetti in un file pickle in modo da non dover riestrarre tutto ogni volta\n",
    "    with open('objs.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "        pickle.dump([train, test, validat_x, dev_x], f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"objs.pkl\",\"rb\") as f:  # Python 3: open(..., 'rb')\n",
    "    train, test, validat_x, dev_x = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estrazione embedding testo+immagini dei diversi dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x,y,y_total = convert_to_model(train)\n",
    "input_test = convert_to_model(test)\n",
    "input_validation,y2,y_total2 = convert_to_model(validat_x)\n",
    "input_dev,y3,y_total3 = convert_to_model(dev_x)\n",
    "\n",
    "#normalizzazione non porta migliorie, quindi è stata scritta in modo che sia modificabile, ma non serve\n",
    "#normalizer = layers.Normalization()\n",
    "#normalizer.adapt(input_x)\n",
    "normalizer = lambda x:x\n",
    "\n",
    "#variabili di gestione reti neurali\n",
    "anothervar = input_x.shape[1]\n",
    "shapey = len(y[0])\n",
    "if(task == 0):\n",
    "    shapey_toy = len(y_total[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "funzioni di creazione reti neurali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inpt = layers.Input(shape=(anothervar,))\n",
    "\n",
    "def build_NN1():\n",
    "    layers = keras.layers\n",
    "    NN1 = keras.models.Model\n",
    "    \n",
    "\n",
    "    ##########\n",
    "    l8 = layers.Dense(anothervar//6, activation='relu')(inpt)\n",
    "    l8 = layers.Dropout(0.3)(l8)\n",
    "    l8 = layers.Dense(shapey, activation='linear')(l8)\n",
    "    simg_predictions = layers.Dense(shapey, activation='softmax')(l8)\n",
    "    ##########\n",
    "    NN1 = NN1(inpt,simg_predictions)\n",
    "    return NN1\n",
    "\n",
    "def build_NN2():\n",
    "    \n",
    "    NN2 = keras.models.Model\n",
    "    add_layer = layers.Dense(anothervar//8, activation='relu')(inpt)\n",
    "    l8 = layers.Dropout(0.3)(add_layer)\n",
    "    l8 = layers.Dense(shapey_toy, activation='linear')(l8)\n",
    "    sigm2_extractpredict = layers.Dense(shapey_toy, activation='softmax')(l8)\n",
    "    NN2 = NN2(inpt,sigm2_extractpredict)\n",
    "    return NN2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "manipolazione dataset in modo da poter manipolare train-dev-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_x = input_validation\n",
    "#y = y2\n",
    "#y_total =y_total2\n",
    "\n",
    "input_x = numpy.concatenate([input_x,input_dev])\n",
    "y = numpy.concatenate([y,y3])\n",
    "y_total = numpy.concatenate([y_total,y_total3])\n",
    "input_x = numpy.concatenate([input_x,input_validation])\n",
    "y = numpy.concatenate([y,y2])\n",
    "y_total = numpy.concatenate([y_total,y_total2])\n",
    "\n",
    "#input_validation = numpy.concatenate([input_dev,input_validation])\n",
    "#y2 = numpy.concatenate([y3,y2])\n",
    "#y_total2 = numpy.concatenate([y_total3,y_total2])\n",
    "\n",
    "# ensemble di reti neurali performa peggio di utilizzarne solo 1\n",
    "# il codice è per un ensemble con reti neurali con diversi dataset in allenamento,\n",
    "# ma è stato impostato per usare una sola rete\n",
    "div = 1\n",
    "leng_input = len(input_x)//div\n",
    "\n",
    "input_x = [input_x[j*leng_input:(j+1)*leng_input] for j in range(div)]\n",
    "y = [y[j*leng_input:(j+1)*leng_input] for j in range(div)]\n",
    "y_tot = [y_total[j*leng_input:(j+1)*leng_input] for j in range(div)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impostando il codice bene è possibile riallenare le reti\n",
    "# la logica era però usa e getta e non è stata sviluppata completamente \n",
    "\n",
    "retrain = False\n",
    "if not retrain:\n",
    "    listt_NN1 = []\n",
    "for j in range(div):\n",
    "    iter = input_x[j]\n",
    "    y_iter = y[j]\n",
    "    if not retrain:\n",
    "        NN1 = build_NN1()\n",
    "        NN1.compile(loss=['binary_crossentropy'], optimizer='adam', metrics=['accuracy'])\n",
    "        history = NN1.fit(x=normalizer(iter),y=y_iter,validation_data=(normalizer(input_validation),y2),batch_size=128, epochs=8)\n",
    "        retrain=True\n",
    "    else:\n",
    "        NN1 = NN1\n",
    "        \n",
    "    #cerco di ridurre il più possibile la loss di validation\n",
    "    NN1.compile(loss=['binary_crossentropy'], optimizer='sgd', metrics=['accuracy'])                                        #1000\n",
    "    history = NN1.fit(x=normalizer(iter),y=y_iter,validation_data=(normalizer(input_validation),y2),batch_size=8500, epochs=1*(1+j))\n",
    "    NN1.acc = history.history['val_accuracy']\n",
    "    listt_NN1.append(NN1)\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "codice non utilizzato per il modello finale, ma su cui sono stati fatti dei test di predizione del numero di labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrain = False\n",
    "#if not retrain:\n",
    "#    listt_NN2 = []\n",
    "#or j in range(div):\n",
    "#   if not retrain:\n",
    "#       NN2 = build_NN2()\n",
    "#   else:\n",
    "#       NN2 = listt_NN2[j]\n",
    "#   iter = input_x[j]\n",
    "#   y_iter = y_tot[j]\n",
    "#   NN2.compile(loss=['categorical_crossentropy'], optimizer='adam', metrics=['accuracy'])\n",
    "##   history = NN2.fit(x=normalizer(iter),y=y_iter,validation_data=(normalizer(input_validation),y_total2),batch_size=128, epochs=3)\n",
    "##   NN2.compile(loss=['categorical_crossentropy'], optimizer='sgd', metrics=['accuracy'])\n",
    "##   history = NN2.fit(x=normalizer(iter),y=y_iter,validation_data=(normalizer(input_validation),y_total2),batch_size=8500, epochs=65)\n",
    "##   listt_NN2.append(NN2)\n",
    "##\n",
    "#plt.plot(history.history['loss'])\n",
    "#plt.plot(history.history['val_loss'])\n",
    "#plt.title('model loss')\n",
    "#plt.ylabel('loss')\n",
    "#plt.xlabel('epoch')\n",
    "#plt.legend(['train', 'val'], loc='upper left')\n",
    "#plt.show()#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listt_NN1 = [NN1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "funzione di supporto per estrazione predizioni e per convertire i risultati in json per mandarli al semEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 1\n",
    "l=list(var)\n",
    "def pred_to_json_ensemble(list_NN1,list_NN2,input_validation,validat_x,filename):\n",
    "    inp = normalizer(input_validation)\n",
    "    k = list_NN1[0].predict(inp,verbose=0)\n",
    "    for v in list_NN1[1:]:\n",
    "        k = k + v.predict(inp,verbose=0)\n",
    "    res = k\n",
    "    \"\"\"\n",
    "    k = list_NN2[0].predict(inp,verbose=0)\n",
    "    for v in list_NN2[1:]:\n",
    "        k = k + v.predict(inp,verbose=0)\n",
    "    \"\"\"\n",
    "    res = (res,k)\n",
    "    \n",
    "    #res = (NN1.predict(inp,verbose=0),NN2.predict(inp,verbose=0))\n",
    "    s = []\n",
    "    for v,k in zip(res[0],res[1]):\n",
    "        # prima provavo a prevedere il numero di classi in base ad una rete neurale secondaria\n",
    "        \"\"\"\n",
    "        c=(numpy.argmax(k)+2)\n",
    "        if c > len(k):\n",
    "            c = k-1\n",
    "        if c == 0:\n",
    "            c=1\n",
    "        ind = numpy.argpartition(v,-c)[-c:]\n",
    "        fin = [1 if x in ind else 0 for x in range(len(v))]\n",
    "        \"\"\"\n",
    "        # treeshold calcolato in validazione, metodo che non usa la seconda neural network\n",
    "        if task == 0:\n",
    "            fin = [1 if v[x]> 0.215*div else 0 for x in range(len(v))]\n",
    "        else:\n",
    "            m = max(v)\n",
    "            fin = [1 if m == v[x] else 0 for x in range(len(v))]\n",
    "        \n",
    "        s.append(fin)\n",
    "        \n",
    "    s = numpy.array(s)\n",
    "    k = numpy.array([((lambda mx:[1 if mx==x else 0 for x in range(6)]) ((lambda v:numpy.argmax(v))(j))) for j in res[1]])\n",
    "    newdict = []\n",
    "    for v,j in zip(validat_x,s):\n",
    "        dic = {}\n",
    "        labelcontainer = []\n",
    "        i = 0\n",
    "        while i<len(l):\n",
    "            if(j[i]==1):\n",
    "                #print(l[i])\n",
    "                labelcontainer.append(l[i])\n",
    "            i+=1\n",
    "        \n",
    "        if task == 0:\n",
    "            dic[\"labels\"] = labelcontainer\n",
    "        else:\n",
    "            dic[\"label\"] = labelcontainer[0]\n",
    "        dic[\"id\"]=v[\"id\"]\n",
    "        dic[\"text\"]=v[\"text\"]\n",
    "        newdict.append(dic)\n",
    "    with open(filename, \"w\") as outfile: \n",
    "        json.dump(newdict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listt_NN2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_to_json_ensemble(listt_NN1,listt_NN2,input_validation,validat_x,\"./validation/predictions.json\")\n",
    "pred_to_json_ensemble(listt_NN1,listt_NN2,input_test,test,\"predictions.json.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "codice per modello di rete neurale utilizzato/salvato al semEval, ho utilizzato una tipologia di allenamento custom, su cui ho avuto fortuna nell'effettuare manipolazione del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import keras\n",
    "#NN1 = keras.saving.load_model(\"NN1.keras\")\n",
    "#NN2 = keras.saving.load_model(\"NN2.keras\")\n",
    "#listt_NN1 = [NN1]\n",
    "#listt_NN2 = [NN2]\n",
    "#pred_to_json_ensemble(listt_NN1,listt_NN2,input_validation,validat_x,\"predictions.json\")\n",
    "#pred_to_json_ensemble(listt_NN1,listt_NN2,input_test,test,\"predictions.json.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "funzioni dai salvataggio dei modelli keras quando riuscivo a raggiungere un buon minimo in validazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN1.save(\"NN1.keras\")\n",
    "#NN2.save(\"NN2.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN1.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
